{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32c27cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (4.28.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (1.26.15)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in f:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in f:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in f:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in f:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in f:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4a0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b36ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c145886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target URL: https://pk.indeed.com/jobs?q=Data+Scientist&l=Pakistan\n",
      "Timeout: Job listing did not load.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env pyth\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"Initialize Chrome with stealth settings using your own browser profile (not incognito).\"\"\"\n",
    "    options = Options()\n",
    "    \n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\"\n",
    "    ]\n",
    "    options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "    \n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "   \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def get_indeed_url(job_keyword, location):\n",
    "    \"\"\"Construct the Indeed search URL.\"\"\"\n",
    "    base_url = \"https://pk.indeed.com/jobs\"\n",
    "    query = f\"?q={job_keyword.replace(' ', '+')}&l={location.replace(' ', '+')}\"\n",
    "    return base_url + query\n",
    "\n",
    "def human_like_scroll(driver):\n",
    "    \"\"\"Simulate human-like scrolling with minimal steps.\"\"\"\n",
    "    scroll_script = \"\"\"\n",
    "    var scrollHeight = document.body.scrollHeight;\n",
    "    var currentScroll = 0;\n",
    "    var scrollSteps = %d;\n",
    "    var scrollStep = scrollHeight / scrollSteps;\n",
    "    function smoothScroll() {\n",
    "        if (currentScroll < scrollHeight) {\n",
    "            currentScroll += scrollStep;\n",
    "            window.scrollTo(0, currentScroll);\n",
    "            setTimeout(smoothScroll, %d);\n",
    "        }\n",
    "    }\n",
    "    smoothScroll();\n",
    "    \"\"\"\n",
    "    steps = random.randint(2, 5)\n",
    "    delay = random.randint(100, 200)\n",
    "    driver.execute_script(scroll_script % (steps, delay))\n",
    "    time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "def random_mouse_movement(driver):\n",
    "    \"\"\"Simulate small random mouse movements.\"\"\"\n",
    "    actions = ActionChains(driver)\n",
    "    for _ in range(random.randint(1, 2)):\n",
    "        x_offset = random.randint(-30, 30)\n",
    "        y_offset = random.randint(-30, 30)\n",
    "        actions.move_by_offset(x_offset, y_offset)\n",
    "        actions.pause(random.uniform(0.1, 0.3))\n",
    "    actions.perform()\n",
    "\n",
    "def scrape_job_details(driver, job_url):\n",
    "    \"\"\"Scrape details from an individual job page.\"\"\"\n",
    "    try:\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        time.sleep(random.uniform(0.5, 1.2))\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "        print(f\"Scraping job URL: {job_url}\")\n",
    "        driver.get(job_url)\n",
    "        \n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.jobsearch-JobInfoHeader-title'))\n",
    "        )\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        random_mouse_movement(driver)\n",
    "        \n",
    "        job_title = driver.find_element(By.CSS_SELECTOR, 'h1.jobsearch-JobInfoHeader-title').text\n",
    "        company_name = driver.find_element(By.CSS_SELECTOR, 'div[data-company-name=\"true\"]').text\n",
    "        job_location = driver.find_element(By.CSS_SELECTOR, 'div.jobsearch-JobInfoHeader-subtitle div:last-child').text\n",
    "        job_description = driver.find_element(By.ID, 'jobDescriptionText').text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in scrape_job_details: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        \n",
    "    return {\n",
    "        'job_url': job_url,\n",
    "        'job_role': job_title,\n",
    "        'company': company_name,\n",
    "        'job_location': job_location,\n",
    "        'job_description': job_description\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Scrape only the first job listing from the search results page.\"\"\"\n",
    "    job_keyword = \"Data Scientist\"\n",
    "    location = \"Pakistan\"\n",
    "    \n",
    "    driver = initialize_driver()\n",
    "    url = get_indeed_url(job_keyword, location)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Target URL: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(2.0, 4.0))\n",
    "        human_like_scroll(driver)\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'a.jcs-JobTitle'))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout: Job listing did not load.\")\n",
    "            driver.quit()\n",
    "            return\n",
    "        \n",
    "        first_job = driver.find_element(By.CSS_SELECTOR, 'a.jcs-JobTitle')\n",
    "        ActionChains(driver).move_to_element(first_job).pause(random.uniform(0.2, 0.7)).click().perform()\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "        job_details = scrape_job_details(driver, first_job.get_attribute('href'))\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    if job_details:\n",
    "        df = pd.DataFrame([job_details])\n",
    "        df.to_csv('single_job_data.csv', index=False)\n",
    "        print(\"Saved 1 job to single_job_data.csv\")\n",
    "    else:\n",
    "        print(\"No data to save\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
